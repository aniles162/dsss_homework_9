# -*- coding: utf-8 -*-
"""aichatbot_dsss_9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XcwZ1Ezkpveommqjb9wR9Oe35j8j_FZh
"""

#!pip install python-telegram-bot --upgrade
#!pip install huggingface_hub

import nest_asyncio
import asyncio
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from transformers import GPTNeoForCausalLM, GPT2Tokenizer, pipeline
import torch

# Start more than one Event-Loop -> google colab problem
nest_asyncio.apply()

# Proof if a GPU is available
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# Tokenizer and model (GPTNeo)
try:
    model_path = "EleutherAI/gpt-neo-1.3B"

    tokenizer = GPT2Tokenizer.from_pretrained(model_path)
    model = GPTNeoForCausalLM.from_pretrained(model_path).to(device)

    # Pipeline
    pipe = pipeline("text-generation", model=model, tokenizer=tokenizer, device=0 if device == "cuda" else -1)


    print("GPTNeo loaded successfully!")
except Exception as e:
    print(f"Error: {e}")

eos_token = tokenizer.eos_token_id

# start: how bot is replying
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Hello! I am your fancy AI chat bot. How can I help you?")


async def respond_with_gptneo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text.strip()  # user message

    try:
        generated_response = pipe(user_message, max_length=150, num_return_sequences=1, truncation=True,
                                  temperature=0.7, top_p=0.9, pad_token_id=eos_token, eos_token_id=eos_token,
                                  no_repeat_ngram_size=2, do_sample=True,
                                  early_stopping=True)[0]['generated_text'].split(user_message, 1)[-1].strip()

    except Exception as e:
        print(f"Error during generation: {e}")

    #answer to user
    await update.message.reply_text(generated_response)

def main():
    print("Bot is starting!")
    API_TOKEN = "7793354822:AAHJJSxlKclkn-KiC63vqqDbjp4LuZItOWY"
    application = Application.builder().token(API_TOKEN).build()

    # Handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, respond_with_gptneo))

    print("Bot is running!")

    # Starting bot
    application.run_polling()

if __name__ == "__main__":
    main()